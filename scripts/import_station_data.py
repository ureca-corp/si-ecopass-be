"""
ì—­ ë° ì£¼ì°¨ì¥ ë°ì´í„° ì„í¬íŠ¸ ìŠ¤í¬ë¦½íŠ¸
Excel íŒŒì¼ì„ ì½ì–´ Kakao Maps APIë¡œ ì§€ì˜¤ì½”ë”© í›„ Supabaseì— ì‚½ì…
"""

import os
import re
import time
import json
import pandas as pd
import requests
from typing import Optional, Tuple

# ============================================================================
# ì„¤ì •
# ============================================================================

KAKAO_API_KEY = os.environ.get("KAKAO_API_KEY", "2249828b1d89ea36ac582812f308e713")
STATIONS_FILE = "stations.xlsx"
PARKINGLOTS_FILE = "parkinglots.xlsx"
OUTPUT_DIR = "scripts/output"

# ë…¸ì„ ëª… â†’ ìˆ«ì ë§¤í•‘
LINE_MAPPING = {
    "ëŒ€êµ¬1í˜¸ì„ ": 1,
    "ëŒ€êµ¬2í˜¸ì„ ": 2,
    "ëŒ€êµ¬3í˜¸ì„ ": 3,
    "ëŒ€ê²½ì„ ": 4,
}


# ============================================================================
# ì§€ì˜¤ì½”ë”© í•¨ìˆ˜
# ============================================================================

def geocode_keyword(query: str) -> Tuple[Optional[float], Optional[float]]:
    """
    Kakao í‚¤ì›Œë“œ ê²€ìƒ‰ìœ¼ë¡œ ìœ„ë„/ê²½ë„ ì¡°íšŒ
    ì—­ ì´ë¦„ì´ë‚˜ ì¥ì†Œëª…ìœ¼ë¡œ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©
    """
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    headers = {"Authorization": f"KakaoAK {KAKAO_API_KEY}"}
    params = {"query": query}

    try:
        response = requests.get(url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()

        if data.get("documents"):
            doc = data["documents"][0]
            return float(doc["y"]), float(doc["x"])  # latitude, longitude
    except Exception as e:
        print(f"  âš ï¸ Geocoding error for '{query}': {e}")

    return None, None


def geocode_address(address: str) -> Tuple[Optional[float], Optional[float]]:
    """
    Kakao ì£¼ì†Œ ê²€ìƒ‰ìœ¼ë¡œ ìœ„ë„/ê²½ë„ ì¡°íšŒ
    ì •í™•í•œ ì£¼ì†Œê°€ ìˆì„ ë•Œ ì‚¬ìš©
    """
    url = "https://dapi.kakao.com/v2/local/search/address.json"
    headers = {"Authorization": f"KakaoAK {KAKAO_API_KEY}"}
    params = {"query": address}

    try:
        response = requests.get(url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()

        if data.get("documents"):
            doc = data["documents"][0]
            # address íƒ€ì…ì— ë”°ë¼ ì¢Œí‘œ ìœ„ì¹˜ê°€ ë‹¤ë¦„
            if "address" in doc:
                return float(doc["y"]), float(doc["x"])
            elif "road_address" in doc and doc["road_address"]:
                return float(doc["y"]), float(doc["x"])
    except Exception as e:
        print(f"  âš ï¸ Address geocoding error for '{address}': {e}")

    return None, None


# ============================================================================
# ë°ì´í„° ì •ê·œí™” í•¨ìˆ˜
# ============================================================================

def normalize_distance(distance_str: str) -> Optional[int]:
    """
    ê±°ë¦¬ ë¬¸ìì—´ì„ ìˆ«ì(ë¯¸í„°)ë¡œ ë³€í™˜
    ì˜ˆ: "310m" â†’ 310, "150" â†’ 150, "ì •ë³´ì—†ìŒ" â†’ None
    """
    if pd.isna(distance_str) or distance_str == "ì •ë³´ì—†ìŒ":
        return None

    # 'm' ì œê±°í•˜ê³  ìˆ«ìë§Œ ì¶”ì¶œ
    match = re.search(r"(\d+)", str(distance_str))
    if match:
        return int(match.group(1))
    return None


def normalize_fee_info(fee_str: str) -> Optional[str]:
    """
    ìš”ê¸ˆ ì •ë³´ ì •ê·œí™”
    """
    if pd.isna(fee_str) or fee_str == "ì •ë³´ì—†ìŒ":
        return None
    return str(fee_str)


# ============================================================================
# ì—­ ë°ì´í„° ì²˜ë¦¬
# ============================================================================

def process_stations() -> list[dict]:
    """
    stations.xlsx íŒŒì¼ì„ ì½ì–´ ì§€ì˜¤ì½”ë”© í›„ ë°ì´í„° ë°˜í™˜
    """
    print("\nğŸ“ ì—­(Stations) ë°ì´í„° ì²˜ë¦¬ ì¤‘...")

    # ì²« í–‰ë„ ë°ì´í„°ì´ë¯€ë¡œ header=None
    df = pd.read_excel(STATIONS_FILE, header=None, names=["name", "line", "address"])

    stations = []
    total = len(df)

    for idx, row in df.iterrows():
        name = row["name"]
        line = row["line"]
        address = row["address"]

        # ë…¸ì„  ë²ˆí˜¸ ë³€í™˜
        line_number = LINE_MAPPING.get(line)
        if line_number is None:
            print(f"  âš ï¸ Unknown line: {line} for station {name}")
            continue

        # ì§€ì˜¤ì½”ë”© - ì—­ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰ (ë” ì •í™•í•¨)
        search_query = f"ëŒ€êµ¬ {name}"
        lat, lng = geocode_keyword(search_query)

        # í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ ì£¼ì†Œë¡œ ì‹œë„
        if lat is None:
            lat, lng = geocode_address(address)

        if lat is None:
            print(f"  âŒ Failed to geocode: {name} ({address})")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€êµ¬ ì¤‘ì‹¬ ì¢Œí‘œ ì‚¬ìš© (ë‚˜ì¤‘ì— ìˆ˜ì • í•„ìš”)
            lat, lng = 35.8714, 128.6014

        stations.append({
            "name": name,
            "line_number": line_number,
            "latitude": lat,
            "longitude": lng,
            "address": address,  # ì°¸ê³ ìš©
        })

        print(f"  [{idx+1}/{total}] {name} ({line}) â†’ ({lat:.6f}, {lng:.6f})")

        # API ì†ë„ ì œí•œ ë°©ì§€ (ì´ˆë‹¹ 10íšŒ ì œí•œ)
        time.sleep(0.1)

    print(f"\nâœ… ì´ {len(stations)}ê°œ ì—­ ì²˜ë¦¬ ì™„ë£Œ")
    return stations


# ============================================================================
# ì£¼ì°¨ì¥ ë°ì´í„° ì²˜ë¦¬
# ============================================================================

def process_parking_lots(station_name_to_id: dict[str, str]) -> list[dict]:
    """
    parkinglots.xlsx íŒŒì¼ì„ ì½ì–´ ì§€ì˜¤ì½”ë”© í›„ ë°ì´í„° ë°˜í™˜
    station_name_to_id: ì—­ ì´ë¦„ â†’ station_id ë§¤í•‘
    """
    print("\nğŸ…¿ï¸ ì£¼ì°¨ì¥(Parking Lots) ë°ì´í„° ì²˜ë¦¬ ì¤‘...")

    df = pd.read_excel(PARKINGLOTS_FILE)

    parking_lots = []
    total = len(df)

    for idx, row in df.iterrows():
        name = row["ì£¼ì°¨ì¥ëª…"]
        station_name = row["ê°€ê¹Œìš´ ì—­"]
        fee_info = normalize_fee_info(row["ì´ìš©ìš”ê¸ˆ"])
        distance = normalize_distance(row["ê±°ë¦¬"])
        address = row["ì£¼ì†Œ"]
        operating_hours = row["ìš´ì˜ì‹œê°„"] if pd.notna(row["ìš´ì˜ì‹œê°„"]) else None

        # station_id ì°¾ê¸°
        station_id = station_name_to_id.get(station_name)
        if station_id is None:
            # ì—­ ì´ë¦„ì— 'ì—­' ì ‘ë¯¸ì‚¬ ì²˜ë¦¬
            alt_name = station_name.replace("ì—­", "") + "ì—­" if "ì—­" not in station_name else station_name
            station_id = station_name_to_id.get(alt_name)

        if station_id is None:
            print(f"  âš ï¸ Station not found: {station_name} for parking lot {name}")
            continue

        # ì§€ì˜¤ì½”ë”© - ì£¼ì°¨ì¥ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰
        search_query = f"ëŒ€êµ¬ {name}"
        lat, lng = geocode_keyword(search_query)

        # í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ ì£¼ì†Œë¡œ ì‹œë„
        if lat is None and pd.notna(address):
            lat, lng = geocode_address(str(address))

        if lat is None:
            print(f"  âŒ Failed to geocode: {name} ({address})")
            lat, lng = 35.8714, 128.6014  # ê¸°ë³¸ê°’

        # ìš”ê¸ˆ ì •ë³´ ì¡°í•©
        full_fee_info = fee_info
        if operating_hours and operating_hours != "ì •ë³´ì—†ìŒ":
            full_fee_info = f"{fee_info or 'ì •ë³´ì—†ìŒ'} (ìš´ì˜: {operating_hours})"

        parking_lots.append({
            "station_id": station_id,  # ë‚˜ì¤‘ì— ì‹¤ì œ IDë¡œ ëŒ€ì²´
            "station_name": station_name,  # ì°¸ì¡°ìš©
            "name": name,
            "address": str(address) if pd.notna(address) else "",
            "latitude": lat,
            "longitude": lng,
            "distance_to_station_m": distance,
            "fee_info": full_fee_info,
        })

        print(f"  [{idx+1}/{total}] {name} (ì—­: {station_name}) â†’ ({lat:.6f}, {lng:.6f})")

        time.sleep(0.1)

    print(f"\nâœ… ì´ {len(parking_lots)}ê°œ ì£¼ì°¨ì¥ ì²˜ë¦¬ ì™„ë£Œ")
    return parking_lots


# ============================================================================
# SQL ìƒì„±
# ============================================================================

def generate_stations_sql(stations: list[dict]) -> str:
    """
    ì—­ ë°ì´í„°ë¥¼ SQL INSERT ë¬¸ìœ¼ë¡œ ë³€í™˜
    """
    lines = [
        "-- ì—­(Stations) ë°ì´í„° ì‚½ì…",
        "-- Generated by import_station_data.py",
        "",
        "INSERT INTO public.stations (name, line_number, location)",
        "VALUES"
    ]

    values = []
    for s in stations:
        # PostGIS geography í¬ë§·: ST_MakePoint(longitude, latitude)
        value = f"  ('{s['name']}', {s['line_number']}, ST_MakePoint({s['longitude']}, {s['latitude']})::geography)"
        values.append(value)

    lines.append(",\n".join(values) + ";")

    return "\n".join(lines)


def generate_parking_lots_sql(parking_lots: list[dict]) -> str:
    """
    ì£¼ì°¨ì¥ ë°ì´í„°ë¥¼ SQL INSERT ë¬¸ìœ¼ë¡œ ë³€í™˜
    station_idëŠ” ì„œë¸Œì¿¼ë¦¬ë¡œ ì²˜ë¦¬
    """
    lines = [
        "-- ì£¼ì°¨ì¥(Parking Lots) ë°ì´í„° ì‚½ì…",
        "-- Generated by import_station_data.py",
        "",
    ]

    for p in parking_lots:
        # station_idë¥¼ ì„œë¸Œì¿¼ë¦¬ë¡œ ì¡°íšŒ
        name_escaped = p['name'].replace("'", "''")
        address_escaped = p['address'].replace("'", "''") if p['address'] else ""
        fee_info_escaped = p['fee_info'].replace("'", "''") if p['fee_info'] else ""
        station_name = p['station_name'].replace("'", "''")

        distance = p['distance_to_station_m']
        distance_sql = str(distance) if distance is not None else "NULL"
        fee_sql = f"'{fee_info_escaped}'" if p['fee_info'] else "NULL"

        sql = f"""INSERT INTO public.parking_lots (station_id, name, address, location, distance_to_station_m, fee_info)
SELECT id, '{name_escaped}', '{address_escaped}', ST_MakePoint({p['longitude']}, {p['latitude']})::geography, {distance_sql}, {fee_sql}
FROM public.stations
WHERE name = '{station_name}'
LIMIT 1;
"""
        lines.append(sql)

    return "\n".join(lines)


# ============================================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸš‡ SI-EcoPass ì—­/ì£¼ì°¨ì¥ ë°ì´í„° ì„í¬íŠ¸")
    print("=" * 60)

    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # 1. ì—­ ë°ì´í„° ì²˜ë¦¬
    stations = process_stations()

    # 2. SQL ìƒì„± (ì—­)
    stations_sql = generate_stations_sql(stations)
    stations_sql_path = os.path.join(OUTPUT_DIR, "01_insert_stations.sql")
    with open(stations_sql_path, "w", encoding="utf-8") as f:
        f.write(stations_sql)
    print(f"\nğŸ“„ ì—­ SQL ì €ì¥: {stations_sql_path}")

    # 3. ì—­ ì´ë¦„ â†’ ID ë§¤í•‘ (ì„ì‹œ, ì‹¤ì œë¡œëŠ” DBì—ì„œ ì¡°íšŒí•´ì•¼ í•¨)
    # ì—¬ê¸°ì„œëŠ” SQL ìƒì„±ìš©ìœ¼ë¡œ ì—­ ì´ë¦„ë§Œ ì‚¬ìš©
    station_name_to_id = {s["name"]: s["name"] for s in stations}

    # 4. ì£¼ì°¨ì¥ ë°ì´í„° ì²˜ë¦¬
    parking_lots = process_parking_lots(station_name_to_id)

    # 5. SQL ìƒì„± (ì£¼ì°¨ì¥)
    parking_lots_sql = generate_parking_lots_sql(parking_lots)
    parking_lots_sql_path = os.path.join(OUTPUT_DIR, "02_insert_parking_lots.sql")
    with open(parking_lots_sql_path, "w", encoding="utf-8") as f:
        f.write(parking_lots_sql)
    print(f"ğŸ“„ ì£¼ì°¨ì¥ SQL ì €ì¥: {parking_lots_sql_path}")

    # 6. JSON ë°±ì—…
    json_backup = {
        "stations": stations,
        "parking_lots": parking_lots,
    }
    json_path = os.path.join(OUTPUT_DIR, "data_backup.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(json_backup, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“„ JSON ë°±ì—… ì €ì¥: {json_path}")

    print("\n" + "=" * 60)
    print("âœ… ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"   - ì—­: {len(stations)}ê°œ")
    print(f"   - ì£¼ì°¨ì¥: {len(parking_lots)}ê°œ")
    print("=" * 60)
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print(f"  1. {stations_sql_path} ê²€í† ")
    print(f"  2. {parking_lots_sql_path} ê²€í† ")
    print("  3. Supabaseì— SQL ì‹¤í–‰")


if __name__ == "__main__":
    main()
